{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the results directory\n",
    "results_dir = '../results/CWRU Load Division IMGNET Pretrain'\n",
    "\n",
    "# Define the mapping from class indices to class names\n",
    "class_mapping = {\n",
    "    0: 'Class A',\n",
    "    1: 'Class B',\n",
    "    2: 'Class C',\n",
    "    3: \"Class D\"\n",
    "}\n",
    "\n",
    "# Initialize lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "# Iterate over each fold\n",
    "fold_dirs = sorted([d for d in os.listdir(results_dir) if d.startswith('fold')])\n",
    "for fold_dir in fold_dirs:\n",
    "    fold_path = os.path.join(results_dir, fold_dir)\n",
    "    preds_true_file = os.path.join(fold_path, 'preds_true.csv')\n",
    "    \n",
    "    # Read the predictions and true labels\n",
    "    df = pd.read_csv(preds_true_file)\n",
    "    preds = df['preds']\n",
    "    true = df['true']\n",
    "    \n",
    "    # Append to the overall lists\n",
    "    all_preds.extend(preds)\n",
    "    all_true.extend(true)\n",
    "    \n",
    "    # Compute the confusion matrix for this fold\n",
    "    #cm = confusion_matrix(true, preds)\n",
    "    \n",
    "    # Plot the confusion matrix for this fold\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    #sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_mapping.values(), \n",
    "                yticklabels=class_mapping.values())\n",
    "    #plt.title(f'Confusion Matrix for {fold_dir}')\n",
    "    #plt.xlabel('Predicted')\n",
    "    #plt.ylabel('True')\n",
    "    #plt.show()\n",
    "\n",
    "# Compute the general confusion matrix across all folds\n",
    "general_cm = confusion_matrix(all_true, all_preds)\n",
    "\n",
    "# Plot the general confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(general_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_mapping.values(), \n",
    "            yticklabels=class_mapping.values())\n",
    "plt.title('General Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "results_dir = '../results'\n",
    "\n",
    "# Define the metrics to analyze\n",
    "metrics = ['f1_score', 'accuracy_score']\n",
    "\n",
    "# Initialize a dictionary to store metrics for each method\n",
    "method_metrics = {}\n",
    "\n",
    "# Iterate over each method folder\n",
    "method_folders = [d for d in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, d))]\n",
    "for method in method_folders:\n",
    "    method_path = os.path.join(results_dir, method)\n",
    "    \n",
    "    # Initialize a list to store metrics for all folds of this method\n",
    "    method_metrics[method] = {metric: [] for metric in metrics}\n",
    "    \n",
    "    # Iterate over each fold in the method folder\n",
    "    fold_dirs = sorted([d for d in os.listdir(method_path) if d.startswith('fold')])\n",
    "    for fold_dir in fold_dirs:\n",
    "        fold_path = os.path.join(method_path, fold_dir)\n",
    "        test_results_file = os.path.join(fold_path, 'test_results.csv')\n",
    "        \n",
    "        # Read the test results for this fold\n",
    "        df = pd.read_csv(test_results_file)\n",
    "        \n",
    "        # Append metrics to the method's list\n",
    "        for metric in metrics:\n",
    "            method_metrics[method][metric].append(df[metric].values[0])\n",
    "\n",
    "# Convert the metrics into a DataFrame for easier plotting\n",
    "data = []\n",
    "for method, metrics_dict in method_metrics.items():\n",
    "    for metric, values in metrics_dict.items():\n",
    "        for value in values:\n",
    "            data.append({'Method': method, 'Metric': metric, 'Value': value})\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Bar Plot: Mean of each metric for each method (one chart at a time)\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(data=df[df['Metric'] == metric], x='Method', y='Value', palette='viridis', hue='Method')\n",
    "    plt.title(f'Mean {metric} with Standard Deviation')\n",
    "    plt.xlabel('Method')\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Box Plot: Distribution of each metric for each method (one chart at a time)\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=df[df['Metric'] == metric], x='Method', y='Value', palette='viridis', hue='Method')\n",
    "    plt.title(f'Distribution of {metric}')\n",
    "    plt.xlabel('Method')\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(0, 1.01)\n",
    "    plt.show()\n",
    "\n",
    "# Create a summary table for each method\n",
    "summary_table = pd.DataFrame(columns=['Method', 'Metric', 'Mean', 'Std'])\n",
    "\n",
    "for method in method_metrics:\n",
    "    for metric in metrics:\n",
    "        mean_value = pd.Series(method_metrics[method][metric]).mean()\n",
    "        std_value = pd.Series(method_metrics[method][metric]).std()\n",
    "        summary_table = summary_table.append({\n",
    "            'Method': method,\n",
    "            'Metric': metric,\n",
    "            'Mean': mean_value,\n",
    "            'Std': std_value\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Pivot the table for better readability\n",
    "summary_table_pivot = summary_table.pivot(index='Method', columns='Metric', values=['Mean', 'Std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "summary_table_pivot"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
